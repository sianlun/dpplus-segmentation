{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt \n",
    "\n",
    "# This is the full library requirements from my virtualenv including jupyter notebook. \n",
    "# If this is once executed, no need to run it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f22d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import glob\n",
    "import random, csv, json\n",
    "from scipy import ndimage\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcea97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wahlau/Programming/deepspray-seg-tf1.3/compress/Mask_RCNN-2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wahlau/Programming/deepspray-seg-tf1.3/compress/Mask_RCNN-2.1\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.join(os.getcwd(),\"Mask_RCNN-2.1\")\n",
    "%cd Mask_RCNN-2.1\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a113eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wahlau/Programming/deepspray-seg-tf1.3/compress/Mask_RCNN-2.1/mask_rcnn_coco.h5\n",
      "/home/wahlau/Programming/deepspray-seg-tf1.3/compress/Mask_RCNN-2.1/logs\n"
     ]
    }
   ],
   "source": [
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Directory to save logs and model checkpoints\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "print(COCO_WEIGHTS_PATH)\n",
    "print(DEFAULT_LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b71a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationConfig(Config):\n",
    "  \"\"\"Configuration for training on the toy  dataset.\n",
    "  Derives from the base Config class and overrides some values.\n",
    "  \"\"\"\n",
    "  # Give the configuration a recognizable name\n",
    "  NAME = \"deepspray\"\n",
    "\n",
    "  # We use a GPU with 12GB memory, which can fit two images.\n",
    "  # Adjust down if you use a smaller GPU.\n",
    "  IMAGES_PER_GPU = 2\n",
    "\n",
    "  # Number of classes (including background)\n",
    "  NUM_CLASSES = 1 + 1  # Background + dech-lig\n",
    "\n",
    "  # Number of training steps per epoch\n",
    "  STEPS_PER_EPOCH = 100\n",
    "\n",
    "  # Skip detections with < 90% confidence\n",
    "  DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class SegmentationDataset(utils.Dataset):\n",
    "\n",
    "  def load_dataset(self, dataset_dir, subset):\n",
    "    \"\"\"Load a subset of the deepspray dataset.\n",
    "    dataset_dir: Root directory of the dataset.\n",
    "    subset: Subset to load: train or val\n",
    "    \"\"\"\n",
    "    # Add classes. We have only one class to add.\n",
    "    self.add_class(\"detchlgm\", 1, \"detchlgm\")\n",
    "\n",
    "    # Train or validation dataset?\n",
    "    assert subset in [\"train\", \"valid\"]\n",
    "\n",
    "    if(subset == \"train\"):\n",
    "      num_image_set = 1000\n",
    "      label_file = os.path.join(dataset_dir, \"labels_train_green_30_10_2021.json\")\n",
    "    else:\n",
    "      num_image_set = 200\n",
    "      label_file = os.path.join(dataset_dir, \"labels_valid_green_30_10_2021.json\")\n",
    "\n",
    "    dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    annotations = json.load(open(label_file))\n",
    "\n",
    "    for i in range (num_image_set):\n",
    "      imgurl = os.path.join(dataset_dir, str(i)+\".png\")\n",
    "      image = skimage.io.imread(imgurl)\n",
    "      height, width = image.shape[:2]\n",
    "\n",
    "      dc_from_json = annotations[i]\n",
    "      polygons = []\n",
    "      for j, p in enumerate(dc_from_json):\n",
    "        p[1] = [j*height for j in p[1]]\n",
    "        p[0] = [j*width for j in p[0]]\n",
    "        polygons.append([p[0],p[1]])\n",
    "\n",
    "      self.add_image(\n",
    "          \"detchlgm\",\n",
    "          image_id=str(i)+\".png\",  # use file name as a unique image id\n",
    "          path=imgurl,\n",
    "          width=width, height=height,\n",
    "          polygons=polygons)\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    \"\"\"Generate instance masks for an image.\n",
    "    Returns:\n",
    "    masks: A bool array of shape [height, width, instance count] with\n",
    "        one mask per instance.\n",
    "    class_ids: a 1D array of class IDs of the instance masks.\n",
    "    \"\"\"\n",
    "    # If not a balloon dataset image, delegate to parent class.\n",
    "    image_info = self.image_info[image_id]\n",
    "    if image_info[\"source\"] != \"detchlgm\":\n",
    "        return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "    # Convert polygons to a bitmap mask of shape\n",
    "    # [height, width, instance_count]\n",
    "    info = self.image_info[image_id]\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                    dtype=np.uint8)\n",
    "    for i, p in enumerate(info[\"polygons\"]):\n",
    "        # Get indexes of pixels inside the polygon and set them to 1\n",
    "        rr, cc = skimage.draw.polygon(p[1], p[0])\n",
    "        mask[rr, cc, i] = 1\n",
    "\n",
    "    # Return mask, and array of class IDs of each instance. Since we have\n",
    "    # one class ID only, we return an array of 1s\n",
    "    return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "  def image_reference(self, image_id):\n",
    "    \"\"\"Return the path of the image.\"\"\"\n",
    "    info = self.image_info[image_id]\n",
    "    if info[\"source\"] == \"detchlgm\":\n",
    "        return info[\"path\"]\n",
    "    else:\n",
    "        super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "def load_dataset_images(dataset):\n",
    "  # Train or evaluate\n",
    "  dataset_train = SegmentationDataset()\n",
    "  dataset_train.load_dataset(dataset, \"train\")\n",
    "  dataset_train.prepare()\n",
    "\n",
    "  # Validation dataset\n",
    "  dataset_val = SegmentationDataset()\n",
    "  dataset_val.load_dataset(dataset, \"valid\")\n",
    "  dataset_val.prepare()\n",
    "  return dataset_train,dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ba09e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           deepspray\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/wahlau/Programming/deepspray-seg-tf1.3/venv3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/wahlau/Programming/deepspray-seg-tf1.3/venv3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/wahlau/Programming/deepspray-seg-tf1.3/venv3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Loading weights  /home/wahlau/Programming/deepspray-seg-tf1.3/compress/Mask_RCNN-2.1/mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "config = SegmentationConfig()\n",
    "config.display()\n",
    "command = \"train\"\n",
    "logs = DEFAULT_LOGS_DIR\n",
    "weights = \"coco\"\n",
    "\n",
    "if command == \"train\":\n",
    "  model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=logs)\n",
    "else:\n",
    "  model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=logs)\n",
    "\n",
    "if weights.lower() == \"coco\":\n",
    "  weights_path = COCO_WEIGHTS_PATH\n",
    "    # Download weights file\n",
    "    # if not os.path.exists(weights_path):\n",
    "    #     utils.download_trained_weights(weights_path)\n",
    "elif weights.lower() == \"last\":\n",
    "    # Find last trained weights\n",
    "  weights_path = model.find_last()[1]\n",
    "elif weights.lower() == \"imagenet\":\n",
    "    # Start from ImageNet trained weights\n",
    "  weights_path = model.get_imagenet_weights()\n",
    "else:\n",
    "  weights_path = weights\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "if weights.lower() == \"coco\":\n",
    "    # Exclude the last layers because they require a matching\n",
    "    # number of classes\n",
    "    model.load_weights(weights_path, by_name=True, exclude=[\n",
    "        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "        \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "else:\n",
    "    model.load_weights(weights_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a083dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train,dataset_val = load_dataset_images(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/wahlau/Programming/deepspray-seg-tf1.3/compress/Mask_RCNN-2.1/logs/deepspray20211104T2302/mask_rcnn_deepspray_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/wahlau/Programming/deepspray-seg-tf1.3/venv3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "  1/100 [..............................] - ETA: 3473s - loss: 3.7009 - rpn_class_loss: 0.3255 - rpn_bbox_loss: 0.3770 - mrcnn_class_loss: 1.1566 - mrcnn_bbox_loss: 0.9246 - mrcnn_mask_loss: 0.9171"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')\n",
    "\n",
    "# this should be done. The trained weights are inside the logs directory. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
