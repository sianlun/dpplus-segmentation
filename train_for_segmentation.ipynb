{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61c2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt \n",
    "\n",
    "# This is the full library requirements from my virtualenv including jupyter notebook. \n",
    "# If this is once executed, no need to run it here\n",
    "\n",
    "## 4.11.2021 - https://github.com/leekunhee/Mask_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f22d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import glob\n",
    "import random, csv, json\n",
    "from scipy import ndimage\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcea97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wahlau/Programming/refat/compress/Mask_RCNN-master/mrcnn\n",
      "/home/wahlau/Programming/refat/compress/Mask_RCNN-master/mrcnn\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.join(os.getcwd(),\"Mask_RCNN-master/mrcnn\")\n",
    "\n",
    "#%cd Mask_RCNN-2.1\n",
    "%cd Mask_RCNN-master/mrcnn\n",
    "from config import Config\n",
    "import utils\n",
    "import model as modellib\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a113eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wahlau/Programming/refat/compress/Mask_RCNN-master/mrcnn/mask_rcnn_coco.h5\n",
      "/home/wahlau/Programming/refat/compress/Mask_RCNN-master/mrcnn/logs\n"
     ]
    }
   ],
   "source": [
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Directory to save logs and model checkpoints\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "print(COCO_WEIGHTS_PATH)\n",
    "print(DEFAULT_LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b71a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationConfig(Config):\n",
    "  \"\"\"Configuration for training on the toy  dataset.\n",
    "  Derives from the base Config class and overrides some values.\n",
    "  \"\"\"\n",
    "  # Give the configuration a recognizable name\n",
    "  NAME = \"deepspray\"\n",
    "\n",
    "  # We use a GPU with 12GB memory, which can fit two images.\n",
    "  # Adjust down if you use a smaller GPU.\n",
    "  IMAGES_PER_GPU = 2\n",
    "\n",
    "  # Number of classes (including background)\n",
    "  NUM_CLASSES = 1 + 1  # Background + dech-lig\n",
    "\n",
    "  # Number of training steps per epoch\n",
    "  STEPS_PER_EPOCH = 100\n",
    "\n",
    "  # Skip detections with < 90% confidence\n",
    "  DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class SegmentationDataset(utils.Dataset):\n",
    "\n",
    "  def load_dataset(self, dataset_dir, subset):\n",
    "    \"\"\"Load a subset of the deepspray dataset.\n",
    "    dataset_dir: Root directory of the dataset.\n",
    "    subset: Subset to load: train or val\n",
    "    \"\"\"\n",
    "    # Add classes. We have only one class to add.\n",
    "    self.add_class(\"detchlgm\", 1, \"detchlgm\")\n",
    "\n",
    "    # Train or validation dataset?\n",
    "    assert subset in [\"train\", \"valid\"]\n",
    "\n",
    "    if(subset == \"train\"):\n",
    "      num_image_set = 1000\n",
    "      label_file = os.path.join(dataset_dir, \"labels_train_green_30_10_2021.json\")\n",
    "    else:\n",
    "      num_image_set = 200\n",
    "      label_file = os.path.join(dataset_dir, \"labels_valid_green_30_10_2021.json\")\n",
    "\n",
    "    dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    annotations = json.load(open(label_file))\n",
    "\n",
    "    for i in range (num_image_set):\n",
    "      imgurl = os.path.join(dataset_dir, str(i)+\".png\")\n",
    "      image = skimage.io.imread(imgurl)\n",
    "      height, width = image.shape[:2]\n",
    "\n",
    "      dc_from_json = annotations[i]\n",
    "      polygons = []\n",
    "      for j, p in enumerate(dc_from_json):\n",
    "        p[1] = [j*height for j in p[1]]\n",
    "        p[0] = [j*width for j in p[0]]\n",
    "        polygons.append([p[0],p[1]])\n",
    "\n",
    "      self.add_image(\n",
    "          \"detchlgm\",\n",
    "          image_id=str(i)+\".png\",  # use file name as a unique image id\n",
    "          path=imgurl,\n",
    "          width=width, height=height,\n",
    "          polygons=polygons)\n",
    "\n",
    "  def load_mask(self, image_id):\n",
    "    \"\"\"Generate instance masks for an image.\n",
    "    Returns:\n",
    "    masks: A bool array of shape [height, width, instance count] with\n",
    "        one mask per instance.\n",
    "    class_ids: a 1D array of class IDs of the instance masks.\n",
    "    \"\"\"\n",
    "    # If not a balloon dataset image, delegate to parent class.\n",
    "    image_info = self.image_info[image_id]\n",
    "    if image_info[\"source\"] != \"detchlgm\":\n",
    "        return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "    # Convert polygons to a bitmap mask of shape\n",
    "    # [height, width, instance_count]\n",
    "    info = self.image_info[image_id]\n",
    "    mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                    dtype=np.uint8)\n",
    "    for i, p in enumerate(info[\"polygons\"]):\n",
    "        # Get indexes of pixels inside the polygon and set them to 1\n",
    "        rr, cc = skimage.draw.polygon(p[1], p[0])\n",
    "        mask[rr, cc, i] = 1\n",
    "\n",
    "    # Return mask, and array of class IDs of each instance. Since we have\n",
    "    # one class ID only, we return an array of 1s\n",
    "    return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "  def image_reference(self, image_id):\n",
    "    \"\"\"Return the path of the image.\"\"\"\n",
    "    info = self.image_info[image_id]\n",
    "    if info[\"source\"] == \"detchlgm\":\n",
    "        return info[\"path\"]\n",
    "    else:\n",
    "        super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "def load_dataset_images(dataset):\n",
    "  # Train or evaluate\n",
    "  dataset_train = SegmentationDataset()\n",
    "  dataset_train.load_dataset(dataset, \"train\")\n",
    "  dataset_train.prepare()\n",
    "\n",
    "  # Validation dataset\n",
    "  dataset_val = SegmentationDataset()\n",
    "  dataset_val.load_dataset(dataset, \"valid\")\n",
    "  dataset_val.prepare()\n",
    "  return dataset_train,dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ba09e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           deepspray\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  /home/wahlau/Programming/refat/compress/Mask_RCNN-master/mrcnn/mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "config = SegmentationConfig()\n",
    "config.display()\n",
    "command = \"train\"\n",
    "logs = DEFAULT_LOGS_DIR\n",
    "weights = \"coco\"\n",
    "\n",
    "if command == \"train\":\n",
    "  model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=logs)\n",
    "else:\n",
    "  model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=logs)\n",
    "\n",
    "if weights.lower() == \"coco\":\n",
    "  weights_path = COCO_WEIGHTS_PATH\n",
    "    # Download weights file\n",
    "    # if not os.path.exists(weights_path):\n",
    "    #     utils.download_trained_weights(weights_path)\n",
    "elif weights.lower() == \"last\":\n",
    "    # Find last trained weights\n",
    "  weights_path = model.find_last()[1]\n",
    "elif weights.lower() == \"imagenet\":\n",
    "    # Start from ImageNet trained weights\n",
    "  weights_path = model.get_imagenet_weights()\n",
    "else:\n",
    "  weights_path = weights\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "if weights.lower() == \"coco\":\n",
    "    # Exclude the last layers because they require a matching\n",
    "    # number of classes\n",
    "    model.load_weights(weights_path, by_name=True, exclude=[\n",
    "        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "        \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "else:\n",
    "    model.load_weights(weights_path, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a083dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train,dataset_val = load_dataset_images(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/wahlau/Programming/refat/compress/Mask_RCNN-master/mrcnn/logs/deepspray20211104T1231/mask_rcnn_deepspray_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val, learning_rate=config.LEARNING_RATE, epochs=100, layers='heads')\n",
    "\n",
    "# this should be done. The trained weights are inside the logs directory. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
